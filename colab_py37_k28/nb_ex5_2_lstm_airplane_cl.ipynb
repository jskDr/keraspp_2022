{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 시계열 데이터를 예측하는 LSTM 구현\n",
    "LSTM을 이용해 시계열 데이터에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to use CPU\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 라이브러리 패키지 임포트\n",
    "1. LSTM을 이용한 판별망 구현에 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import models, layers\n",
    "\n",
    "from keraspp import skeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 코드 실행 및 결과 보기\n",
    "2. 세부 코드를 보기 전에 머신을 만들고 실행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    machine = Machine() \n",
    "    machine.run(epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 학습하고 평가하기\n",
    "3. 머신 클래스는 시계열 LSTM을 학습하고 평가하는 플랫폼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine():\n",
    "    def __init__(self):\n",
    "        self.data = Dataset()\n",
    "        shape = self.data.X.shape[1:]\n",
    "        self.model = rnn_model(shape)\n",
    "        \n",
    "    def run(self, epochs=400):\n",
    "        d = self.data\n",
    "        X_train, X_test, y_train, y_test = d.X_train, d.X_test, d.y_train, d.y_test\n",
    "        X, y = d.X, d.y\n",
    "        m = self.model \n",
    "        h = m.fit(X_train, y_train, epochs=epochs, validation_data=[X_test, y_test], verbose=0)\n",
    "\n",
    "        skeras.plot_loss(h)\n",
    "        plt.title('History of training')\n",
    "        plt.show()\n",
    "\n",
    "        yp = m.predict(X_test)\n",
    "        print('Loss:', m.evaluate(X_test, y_test))\n",
    "        plt.plot(yp, label='Origial')\n",
    "        plt.plot(y_test, label='Prediction')\n",
    "        plt.legend(loc=0)\n",
    "        plt.title('Validation Results')\n",
    "        plt.show()\n",
    "\n",
    "        yp = m.predict(X_test).reshape(-1)\n",
    "        print('Loss:', m.evaluate(X_test, y_test))  \n",
    "        print(yp.shape, y_test.shape)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['Sample'] = list(range(len(y_test))) * 2\n",
    "        df['Normalized #Passengers'] = np.concatenate([y_test, yp], axis=0)\n",
    "        df['Type'] = ['Original'] * len(y_test) + ['Prediction'] * len(yp)\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.barplot(x=\"Sample\", y=\"Normalized #Passengers\", \n",
    "                    hue=\"Type\", data=df)\n",
    "        plt.ylabel('Normalized #Passengers')\n",
    "        plt.show()\n",
    "        \n",
    "        yp = m.predict(X)\n",
    "\n",
    "        plt.plot(yp, label='Origial')\n",
    "        plt.plot(y, label='Prediction')\n",
    "        plt.legend(loc=0)\n",
    "        plt.title('All Results')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 LSTM 시계열 회귀 모델링\n",
    "4. 시계열 데이터의 회귀 모델링을 위한 LSTM 모델의 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(shape):\n",
    "    m_x = layers.Input(shape=shape) #X.shape[1:]\n",
    "    m_h = layers.LSTM(10)(m_x)\n",
    "    m_y = layers.Dense(1)(m_h)\n",
    "    m = models.Model(m_x, m_y)\n",
    "    m.compile('adam', 'mean_squared_error')\n",
    "    m.summary()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.5 데이터 불러오기 \n",
    "5. 데이터는 Dataset 클래스를 구성해서 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, fname='international-airline-passengers.csv', D=12):\n",
    "        data_dn = load_data(fname=fname)\n",
    "        self.X, self.y = get_Xy(data_dn, D=D)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "            model_selection.train_test_split(self.X, self.y, \n",
    "              test_size=0.2, random_state=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname='international-airline-passengers.csv'):\n",
    "    dataset = pd.read_csv(fname, usecols=[1], engine='python', skipfooter=3)\n",
    "    data = dataset.values.reshape(-1)\n",
    "    plt.plot(data)\n",
    "    plt.xlabel('Time'); plt.ylabel('#Passengers')\n",
    "    plt.title('Original Data')\n",
    "    plt.show()\n",
    "\n",
    "    # data normalize\n",
    "    data_dn = (data - np.mean(data)) / np.std(data) / 5\n",
    "    plt.plot(data_dn)\n",
    "    plt.xlabel('Time'); plt.ylabel('Normalized #Passengers')\n",
    "    plt.title('Normalized data by $E[]$ and $5\\sigma$')\n",
    "    plt.show()\n",
    "    \n",
    "    return data_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(data, D=12):\n",
    "    # make X and y\n",
    "    X_l = []\n",
    "    y_l = []\n",
    "    N = len(data)\n",
    "    assert N > D, \"N should be larger than D, where N is len(data)\"\n",
    "    for ii in range(N-D-1):\n",
    "        X_l.append(data[ii:ii+D])\n",
    "        y_l.append(data[ii+D])\n",
    "    X = np.array(X_l)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = np.array(y_l)\n",
    "    print(X.shape, y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from keras import models, layers\n",
    "import seaborn as sns\n",
    "from keraspp import skeras\n",
    "\n",
    "# %%\n",
    "def main():        \n",
    "    machine = Machine() \n",
    "    machine.run(epochs=400)\n",
    "\n",
    "class Machine():\n",
    "    def __init__(self):\n",
    "        self.data = Dataset()\n",
    "        shape = self.data.X.shape[1:]\n",
    "        self.model = rnn_model(shape)\n",
    "        \n",
    "    def run(self, epochs=400):\n",
    "        d = self.data\n",
    "        X_train, X_test, y_train, y_test = d.X_train, d.X_test, d.y_train, d.y_test\n",
    "        X, y = d.X, d.y\n",
    "        m = self.model \n",
    "        h = m.fit(X_train, y_train, epochs=epochs, validation_data=[X_test, y_test], verbose=0)\n",
    "\n",
    "        skeras.plot_loss(h)\n",
    "        plt.title('History of training')\n",
    "        plt.show()\n",
    "\n",
    "        yp = m.predict(X_test)\n",
    "        print('Loss:', m.evaluate(X_test, y_test))\n",
    "        plt.plot(yp, label='Origial')\n",
    "        plt.plot(y_test, label='Prediction')\n",
    "        plt.legend(loc=0)\n",
    "        plt.title('Validation Results')\n",
    "        plt.show()\n",
    "\n",
    "        yp = m.predict(X_test).reshape(-1)\n",
    "        print('Loss:', m.evaluate(X_test, y_test))  \n",
    "        print(yp.shape, y_test.shape)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['Sample'] = list(range(len(y_test))) * 2\n",
    "        df['Normalized #Passengers'] = np.concatenate([y_test, yp], axis=0)\n",
    "        df['Type'] = ['Original'] * len(y_test) + ['Prediction'] * len(yp)\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.barplot(x=\"Sample\", y=\"Normalized #Passengers\", \n",
    "                    hue=\"Type\", data=df)\n",
    "        plt.ylabel('Normalized #Passengers')\n",
    "        plt.show()\n",
    "        \n",
    "        yp = m.predict(X)\n",
    "\n",
    "        plt.plot(yp, label='Origial')\n",
    "        plt.plot(y, label='Prediction')\n",
    "        plt.legend(loc=0)\n",
    "        plt.title('All Results')\n",
    "        plt.show()\n",
    "\n",
    "def rnn_model(shape):\n",
    "    m_x = layers.Input(shape=shape) #X.shape[1:]\n",
    "    m_h = layers.LSTM(10)(m_x)\n",
    "    m_y = layers.Dense(1)(m_h)\n",
    "    m = models.Model(m_x, m_y)\n",
    "    m.compile('adam', 'mean_squared_error')\n",
    "    m.summary()\n",
    "    return m\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, fname='international-airline-passengers.csv', D=12):\n",
    "        data_dn = load_data(fname=fname)\n",
    "        self.X, self.y = get_Xy(data_dn, D=D)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "           model_selection.train_test_split(self.X, self.y, \n",
    "              test_size=0.2, random_state=42)  \n",
    "\n",
    "def load_data(fname='international-airline-passengers.csv'):\n",
    "    dataset = pd.read_csv(fname, usecols=[1], engine='python', skipfooter=3)\n",
    "    data = dataset.values.reshape(-1)\n",
    "    plt.plot(data)\n",
    "    plt.xlabel('Time'); plt.ylabel('#Passengers')\n",
    "    plt.title('Original Data')\n",
    "    plt.show()\n",
    "\n",
    "    # data normalize\n",
    "    data_dn = (data - np.mean(data)) / np.std(data) / 5\n",
    "    plt.plot(data_dn)\n",
    "    plt.xlabel('Time'); plt.ylabel('Normalized #Passengers')\n",
    "    plt.title('Normalized data by $E[]$ and $5\\sigma$')\n",
    "    plt.show()\n",
    "    \n",
    "    return data_dn\n",
    "\n",
    "def get_Xy(data, D=12):\n",
    "    # make X and y\n",
    "    X_l = []\n",
    "    y_l = []\n",
    "    N = len(data)\n",
    "    assert N > D, \"N should be larger than D, where N is len(data)\"\n",
    "    for ii in range(N-D-1):\n",
    "        X_l.append(data[ii:ii+D])\n",
    "        y_l.append(data[ii+D])\n",
    "    X = np.array(X_l)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y = np.array(y_l)\n",
    "    print(X.shape, y.shape)\n",
    "    return X, y\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
