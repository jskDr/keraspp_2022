{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 컬러 이미지를 분류하는 DNN 구현\n",
    "필기체보다 복잡도가 높은 컬러 이미지들을 DNN으로 분류해봅니다.\n",
    "\n",
    "### 3.3.2 데이터 불러오기\n",
    "컬러 이미지 데이터가 들어 있는 CIFAR-10은 3가지 채널(각각 RGB)로 구성됩니다.\n",
    "\n",
    "1. 데이터를 불러와서 학습을 위한 사전 처리를 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 불러오는 데 필요한 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 불러와서 사전 처리를 할 차례입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H, C = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H * C)\n",
    "    X_test = X_test.reshape(-1, W * H * C)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 DNN 모델링\n",
    "2. DNN 모델은 3.2절에서 사용한 모델에 드롭아웃의 인자 조정을 추가한 형태로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nin, Nh_l, Pd_l, Nout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(layers.Dense(Nh_l[0], activation='relu',\n",
    "                              input_shape=(Nin,), name='Hidden-1'))\n",
    "        self.add(layers.Dropout(Pd_l[0]))\n",
    "\n",
    "        self.add(layers.Dense(Nh_l[1], activation='relu',\n",
    "                              name='Hidden-2'))\n",
    "        self.add(layers.Dropout(Pd_l[1]))\n",
    "\n",
    "        self.add(layers.Dense(Nout, activation='softmax'))\n",
    "\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 학습 효과 분석 \n",
    "3. 학습 효과를 분석하는 코드는 2.2절의 코드를 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 학습 및 성능 평가\n",
    "4. 사진 데이터를 분류하는 학습을 진행한 후 그 성능을 평가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 19:03:37.269928: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1228800000 exceeds 10% of free system memory.\n",
      "2021-09-21 19:03:47.951330: W tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB (rounded to 1228800000)\n",
      "Current allocation summary follows.\n",
      "2021-09-21 19:03:47.951440: I tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc\n",
      "2021-09-21 19:03:47.951470: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (256): \tTotal Chunks: 15, Chunks in use: 15. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 524B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951483: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 800B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951494: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 3.0KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951505: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2048): \tTotal Chunks: 3, Chunks in use: 2. 6.2KiB allocated for chunks. 4.0KiB in use in bin. 3.9KiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951515: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951527: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 8.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951539: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16384): \tTotal Chunks: 4, Chunks in use: 2. 79.2KiB allocated for chunks. 39.5KiB in use in bin. 39.1KiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951549: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951559: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951572: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 156.2KiB allocated for chunks. 156.2KiB in use in bin. 156.2KiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951582: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951592: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 943.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951603: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1048576): \tTotal Chunks: 4, Chunks in use: 2. 4.69MiB allocated for chunks. 2.34MiB in use in bin. 2.34MiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951613: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951623: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951632: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951642: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951651: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951661: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951925: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 243.29MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951954: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 1.14GiB allocated for chunks. 1.14GiB in use in bin. 1.14GiB client-requested in use in bin.\n",
      "2021-09-21 19:03:47.951967: I tensorflow/core/common_runtime/bfc_allocator.cc:957] Bin for 1.14GiB was 256.00MiB, Chunk State: \n",
      "2021-09-21 19:03:47.951976: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 1490052352\n",
      "2021-09-21 19:03:47.951991: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010000 of size 1280 next 1\n",
      "2021-09-21 19:03:47.952000: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010500 of size 256 next 5\n",
      "2021-09-21 19:03:47.952010: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010600 of size 512 next 8\n",
      "2021-09-21 19:03:47.952019: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010800 of size 256 next 12\n",
      "2021-09-21 19:03:47.952027: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010900 of size 256 next 18\n",
      "2021-09-21 19:03:47.952035: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010a00 of size 256 next 21\n",
      "2021-09-21 19:03:47.952044: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010b00 of size 256 next 22\n",
      "2021-09-21 19:03:47.952052: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010c00 of size 512 next 27\n",
      "2021-09-21 19:03:47.952060: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010e00 of size 256 next 30\n",
      "2021-09-21 19:03:47.952069: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502010f00 of size 256 next 33\n",
      "2021-09-21 19:03:47.952077: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502011000 of size 256 next 15\n",
      "2021-09-21 19:03:47.952085: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502011100 of size 256 next 16\n",
      "2021-09-21 19:03:47.952093: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502011200 of size 256 next 17\n",
      "2021-09-21 19:03:47.952103: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502011300 of size 2304 next 19\n",
      "2021-09-21 19:03:47.952118: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502011c00 of size 2048 next 20\n",
      "2021-09-21 19:03:47.952140: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502012400 of size 256 next 34\n",
      "2021-09-21 19:03:47.952162: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502012500 of size 1792 next 32\n",
      "2021-09-21 19:03:47.952178: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502012c00 of size 2048 next 31\n",
      "2021-09-21 19:03:47.952193: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502013400 of size 8960 next 9\n",
      "2021-09-21 19:03:47.952207: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502015700 of size 256 next 10\n",
      "2021-09-21 19:03:47.952220: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502015800 of size 256 next 11\n",
      "2021-09-21 19:03:47.952234: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502015900 of size 20480 next 13\n",
      "2021-09-21 19:03:47.952249: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 50201a900 of size 20224 next 14\n",
      "2021-09-21 19:03:47.952263: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 50201f800 of size 160000 next 24\n",
      "2021-09-21 19:03:47.952279: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502046900 of size 20224 next 29\n",
      "2021-09-21 19:03:47.952293: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 50204b800 of size 20224 next 28\n",
      "2021-09-21 19:03:47.952307: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 502050700 of size 966144 next 2\n",
      "2021-09-21 19:03:47.952400: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 50213c500 of size 256 next 3\n",
      "2021-09-21 19:03:47.952429: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 50213c600 of size 256 next 4\n",
      "2021-09-21 19:03:47.952444: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 50213c700 of size 1229056 next 6\n",
      "2021-09-21 19:03:47.952459: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502268800 of size 1228800 next 7\n",
      "2021-09-21 19:03:47.952474: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 502394800 of size 1228800000 next 23\n",
      "2021-09-21 19:03:47.952489: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 54b774800 of size 1228800 next 26\n",
      "2021-09-21 19:03:47.952505: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 54b8a0800 of size 1228800 next 25\n",
      "2021-09-21 19:03:47.952520: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 54b9cc800 of size 255106304 next 18446744073709551615\n",
      "2021-09-21 19:03:47.952534: I tensorflow/core/common_runtime/bfc_allocator.cc:995]      Summary of in-use Chunks by size: \n",
      "2021-09-21 19:03:47.952554: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 15 Chunks of size 256 totalling 3.8KiB\n",
      "2021-09-21 19:03:47.952569: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2021-09-21 19:03:47.952584: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2021-09-21 19:03:47.952599: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 2048 totalling 4.0KiB\n",
      "2021-09-21 19:03:47.952615: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 20224 totalling 39.5KiB\n",
      "2021-09-21 19:03:47.952632: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 160000 totalling 156.2KiB\n",
      "2021-09-21 19:03:47.952647: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 1228800 totalling 2.34MiB\n",
      "2021-09-21 19:03:47.952662: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1228800000 totalling 1.14GiB\n",
      "2021-09-21 19:03:47.952676: I tensorflow/core/common_runtime/bfc_allocator.cc:1002] Sum Total of in-use chunks: 1.15GiB\n",
      "2021-09-21 19:03:47.952691: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] total_region_allocated_bytes_: 1490052352 memory_limit_: 1490052507 available bytes: 155 curr_region_allocation_bytes_: 2980105216\n",
      "2021-09-21 19:03:47.952713: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats: \n",
      "Limit:                  1490052507\n",
      "InUse:                  1231468288\n",
      "MaxInUse:               1233902336\n",
      "NumAllocs:                      76\n",
      "MaxAllocSize:           1228800000\n",
      "\n",
      "2021-09-21 19:03:47.952734: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************************************************************************_________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1150/394190725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNh_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPd_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mperformace_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    793\u001b[0m       \u001b[0;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[0;32m--> 795\u001b[0;31m           data_adapter.train_validation_split((x, y, sample_weight),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                               shuffle=False))\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m   train_arrays = nest.map_structure(\n\u001b[0m\u001b[1;32m   1338\u001b[0m       functools.partial(_split, indices=train_indices), arrays)\n\u001b[1;32m   1339\u001b[0m   val_arrays = nest.map_structure(\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_split\u001b[0;34m(t, indices)\u001b[0m\n\u001b[1;32m   1333\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   train_arrays = nest.map_structure(\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   4533\u001b[0m               \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4534\u001b[0m               name=None):\n\u001b[0;32m-> 4535\u001b[0;31m   return gather(\n\u001b[0m\u001b[1;32m   4536\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4537\u001b[0m       \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   3753\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3754\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3755\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3756\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3757\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "Pd_l=[0.0, 0.0]\n",
    "Nh_l = [100, 50]\n",
    "number_of_class = 10\n",
    "Nout = number_of_class\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = Data_func()\n",
    "model = DNN(X_train.shape[1], Nh_l, Pd_l, Nout)\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_split=0.2)\n",
    "\n",
    "performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "print('Test Loss and Accuracy ->', performace_test)\n",
    "\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "plot_loss(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3.6 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: ex3_2_dnn_cifar10_cl.py\n",
    "\n",
    "# 1. 데이터 준비\n",
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    L, W, H, C = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H * C)\n",
    "    X_test = X_test.reshape(-1, W * H * C)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "# 2. 분류 DNN 모델 구현\n",
    "from keras import layers, models\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nin, Nh_l, Pd_l, Nout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(layers.Dense(Nh_l[0], activation='relu',\n",
    "                              input_shape=(Nin,), name='Hidden-1'))\n",
    "        self.add(layers.Dropout(Pd_l[0]))\n",
    "\n",
    "        self.add(layers.Dense(Nh_l[1], activation='relu',\n",
    "                              name='Hidden-2'))\n",
    "        self.add(layers.Dropout(Pd_l[1]))\n",
    "\n",
    "        self.add(layers.Dense(Nout, activation='softmax'))\n",
    "\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# 3. 학습 효과 분석\n",
    "from keraspp.skeras import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 4. 분류 DNN 학습 및 테스팅\n",
    "def main(Pd_l=[0.0, 0.0]):\n",
    "    Nh_l = [100, 50]\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = Data_func()\n",
    "    model = DNN(X_train.shape[1], Nh_l, Pd_l, Nout)\n",
    "    history = model.fit(X_train, Y_train, epochs=100, batch_size=100, validation_split=0.2)\n",
    "\n",
    "    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "    print('Test Loss and Accuracy ->', performace_test)\n",
    "\n",
    "    plot_acc(history)\n",
    "    plt.show()\n",
    "    plot_loss(history)\n",
    "    plt.show()\n",
    "\n",
    "main(Pd_l=[0.0, 0.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
